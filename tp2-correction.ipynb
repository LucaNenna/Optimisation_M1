{"cells": [{"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["***\n", "**Approfondissements d'optimisation -- M1 MA 2021/2022 -- Universit\u00e9 Paris-Saclay**\n", "***\n", "\n", "# TP 2 : Projection sur le simplexe et optimisation de portefeuille\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "import scipy.optimize\n", "%matplotlib inline\n", "# la commande suivante agrandit les figures\n", "plt.rcParams['figure.figsize'] = [9.,6.]\n", "\n", "def verifier_gradient(f,g,x0):\n", "    N = len(x0)\n", "    gg = np.zeros(N)\n", "    for i in range(N):\n", "        eps = 1e-4\n", "        e = np.zeros(N)\n", "        e[i] = eps\n", "        gg[i] = (f(x0+e) - f(x0-e))/(2*eps)\n", "    print('erreur numerique dans le calcul du gradient: %g (doit etre petit)' % np.linalg.norm(g(x0)-gg))"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["## I. Projection sur le simplexe\n", "$\\newcommand{\\Rsp}{\\mathbb{R}}$\n", "$\\newcommand{\\sca}[2]{\\langle #1|#2\\rangle}$\n", "$\\newcommand{\\eps}{\\varepsilon}$\n", "$\\newcommand{\\proj}{\\mathrm{proj}}$\n", "Comme dans le troisi\u00e8me exercice de la feuille de TD consacr\u00e9e au calcul de projections, on appelle simplexe l'ensemble \n", "\n", "$$\\Delta = \\{ x\\in \\Rsp_+^n \\mid \\sum_{1\\leq i \\leq n} x_i = 1\\}.$$\n", "\n", "Dans un premier temps, on va chercher \u00e0 calculer la projection d'un point \n", "$y\\in\\Rsp^n$ sur $\\Delta$. Pour cela, on admettra les deux r\u00e9sultats suivants, d\u00e9montr\u00e9s dans le TD:\n", "\n", "- il existe $\\kappa\\in\\Rsp$ tel que $\\sum_{1\\leq i\\leq n} \\max(y_i - \\kappa, 0) = 1$\n", "- la projection de $y$ sur $\\Delta$ s'\u00e9crit alors $\\proj_\\Delta(y) = (\\max(y_i - \\kappa, 0))_{1\\leq i\\leq n}$\n", "\n", "Ainsi, pour trouver la projection d'un point $y\\in\\Rsp^n$ sur le simplexe $\\Delta$, il suffit de trouver $\\kappa\\in\\Rsp$ tel que $g(\\kappa) = 0$ o\u00f9 l'on a pos\u00e9\n", "$$ g(\\kappa) = \\left(\\sum_{1\\leq i\\leq n} \\max(y_i - \\kappa, 0)\\right) -1$$\n", "\n", "\n", "**Q1)** Soit $y = (0.1,1.5,2.1) \\in \\Rsp^3$. \u00c9crire la fonction `g(kappa)` d\u00e9crite ci-dessus. Trouver $\\kappa$ v\u00e9rifiant $g(\\kappa) = 0$ en utilisant la fonction `scipy.optimize.root(g,x0=0,method='anderson').x`."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["1.299997717450157\n"]}], "source": ["y = np.array([0.1,1.5,2.1])\n", "def g(k):\n", "    return np.sum(np.maximum(y-k,0)) - 1.0\n", "\n", "k = scipy.optimize.root(g,x0=0,method='anderson').x\n", "print(k)\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["**Q2)** En s'inspirant du code de la fonction pr\u00e9c\u00e9dente, \u00e9crire une fonction proj_simplexe calculant la projection d'un point $y\\in\\Rsp^n$ sur $\\Delta$. Pour v\u00e9rifier le bon fonctionnement de cette fonction, calculer calculer $p=$`proj_simplexe(y)` pour $y=$`np.random.randn(n)` puis v\u00e9rifier que \n", "\n", "$$ \\forall i\\in\\{1,\\dots,n\\}, \\sca{y - p}{p - e_i} \\geq 0,$$\n", "\n", "o\u00f9 $e_i$ est le $i$\u00e8me vecteur de la base canonique.\n", "\n", "*(Question subsidiaire: pourquoi cette in\u00e9galit\u00e9 doit-elle \u00eatre vraie pour $p = \\proj_\\Delta(y)$ ? Caract\u00e9rise-t-elle la projection sur $\\Delta$?)*\n", "<!-- (dans le cas $n=2$, on peut \u00e9galement tirer quelques points al\u00e9atoirement dans le plan et visualiser le segment qui les relie \u00e0 leur projection sur $\\Delta$) -->"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["1.3913329531327605\n", "0.4749149521297018\n", "1.3740707076598135\n", "0.414850866863518\n", "0.4014555834153901\n", "4.1666584071897717e-10\n", "2.8240212277393324\n", "4.1666581296340155e-10\n", "4.1666578520782593e-10\n", "2.0995510209674544\n"]}], "source": ["def proj_simplexe(y):\n", "    g = lambda k: np.sum(np.maximum(y-k,0)) - 1.0\n", "    sol = scipy.optimize.root(g,x0=0,method='anderson') # scipy.optimize.fsolve(g,0)\n", "    k = sol.x\n", "    return np.maximum(y-k,0)\n", "\n", "# validation: calcul de produits scalaires\n", "n = 10\n", "y = np.random.randn(n)\n", "p = proj_simplexe(y)\n", "for i in range(n):\n", "    ei = np.zeros(n)\n", "    ei[i] = 1\n", "    print(np.dot(y-p, p-ei))\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["## II. Optimisation de portefeuille.\n", "\n", "Dans cette partie, il s'agit de r\u00e9soudre un probl\u00e8me d'optimisation sous contraintes de la forme suivante:\n", "\n", "$$ \\min_{x\\in\\Delta} f(x) \\hbox{ o\u00f9 } f(x) = \\frac{1}{2}\\sca{x}{Qx} + \\frac{1}{2\\eta}(\\sca{r}{x}-r_0)^2, $$\n", "\n", "o\u00f9 $Q \\in \\mathcal{M}_{n,n}(\\Rsp)$ est une matrice sym\u00e9trique d\u00e9finie positive, $r\\in\\Rsp$ est un vecteur et $r_0\\in\\Rsp$ sont donn\u00e9s. Dans la suite, on fixera $\\eta = 10^{-2}$. \n", "\n", "**Motivation:** Ce probl\u00e8me mod\u00e9lise une situation o\u00f9 un investisseur cherche placer un portefeuille en garantissant un certain niveau de rendement $r_0\\in\\Rsp$ tout en minimisant le risque. Plus pr\u00e9cis\u00e9ment, dans ce probl\u00e8me $n$ est le nombre d'actifs (actions, etc.), et la variable $x\\in\\Rsp^n$ d\u00e9crit la strat\u00e9gie d'investissement: $x_i$ d\u00e9crit la fraction du portefeuille que l'on investit dans l'actif $i$. Ainsi, la contrainte $x\\in\\Delta$ mod\u00e9lise:\n", "\n", "- qu'on investit une fraction $x_i$ positive dans chaque actif (contrainte $x_i\\geq 0$);\n", "- et que la somme totale disponible est investie ($\\sum_i x_i = 1$).\n", "\n", "La matrice $Q$ mod\u00e9lise la covariance entre les actifs:\n", "- si $Q_{ij}\\geq 0$, cela signifie que les actifs financiers $i$ et $j$ sont positivement correl\u00e9s, et il est donc risqu\u00e9 d'investir dans les deux en m\u00eame temps. \n", "- au contraire, si $Q_{i,j}<0$, les actifs sont n\u00e9gativement correl\u00e9s, et en investissant dans les deux on diminue le risque. \n", "Le probl\u00e8me d'optimisation qu'on regarde consiste donc \u00e0 trouver une strat\u00e9gie d'investissement ($x\\in \\Delta$) cherchant \u00e0 viser un rendement donn\u00e9 (terme $\\frac{1}{2\\eta}(\\sca{r}{x}-r_0)^2$) tout en minimisant le risque (terme $\\sca{x}{Qx}$).\n", "\n", "En pratique, on consid\u00e8rera les donn\u00e9es suivantes:"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Le code suivant permet de construire la matrice $Q$ \u00e0 partir de donn\u00e9es r\u00e9elles.\n", "# Ne pas h\u00e9siter \u00e0 la d\u00e9commenter et \u00e0 tester avec d'autres choix d'actifs. Pour cela,\n", "# il faut installer le package yfinance en lan\u00e7ant la ligne suivant\n", "# !pip install yfinance\n", "if False: # mettre True pour changer les dates, les actifs, etc\n", "    import yfinance as yf \n", "    import numpy as np\n", "    stocks = ['NFLX','MSFT','BA','AIR']\n", "    closes = np.array([np.array(yf.download(s,'2019-01-01','2020-01-01').Close) for s in stocks]).T\n", "    r = (closes[-1,:] - closes[1,:])/closes[1,:] # rendement sur l'ann\u00e9e 2019\n", "    Q = np.cov(closes - np.mean(closes,0),rowvar=False) # estimation de la covariance entre les valeurs\n", "\n", "Q = np.array([[1199.6242199,  -225.74269344,  270.42617708, -112.31853678],\n", "              [-225.74269344,  224.42514399, -157.75776414,   46.31290714],\n", "              [ 270.42617708, -157.75776414,  600.37115079,  -28.1665365 ],\n", "              [-112.31853678,   46.31290714,  -28.1665365,    21.77422792]])\n", "r = np.array([0.20888442, 0.55953316, 0.00602209, 0.2042723])\n", "r0 = 0.7*np.max(r)\n", "eta = 1e-4"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["**Q1)** Montrer que la fonction $f$ est strictement convexe et que\n", "$\\nabla f(x) = Qx + \\frac{1}{\\eta} (\\sca{r}{x}-r_0) r.$"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["## II.1. M\u00e9thode de gradient projet\u00e9\n", "\n", "**Q2)** \u00c9crire une fonction `f` et `gradf`, et utiliser la fonction `verifier_gradient` pour valider l'impl\u00e9mentation."]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["erreur numerique dans le calcul du gradient: 2.22204e-09 (doit etre petit)\n"]}], "source": ["def f(x):\n", "    return .5*np.dot(x,Q@x) + .5/eta*(np.dot(x,r) - r0)**2\n", "def gradf(x):\n", "    return Q@x + 1/eta*(np.dot(x,r)-r0)*r\n", "\n", "# v\u00e9rification du calcul du gradient\n", "verifier_gradient(f,gradf,np.random.rand(len(r)))"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["**Q3)** Impl\u00e9menter l'algorithme du gradient projet\u00e9 pour r\u00e9soudre le probl\u00e8me avec les donn\u00e9es ci-dessus, i.e.\n", "\n", "$$ \\begin{cases} x^{(0)} = 0_{\\Rsp^n}\\\\\n", "x^{(k+1)} = \\mathrm{proj\\_simplexe}(x^{(k)} - \\tau \\nabla f(x^{(k)})) \n", "\\end{cases}$$ \n", "\n", "Tracer sur deux figures distinctes:\n", "- La suite des valeurs $f(x^{(k)})$ pour $1\\leq k<100$.\n", "- La suite $\\|{x^{k} - x^{(k-1)}}\\|$ pour $1\\leq k<100$ (on pourra mettre les abscisses en \u00e9chelle logarithmique). Pourquoi la convergence de cette suite vers z\u00e9ro est-elle une indication du bon fonctionnement de l'algorithme?\n", "\n", "Pour choisir le param\u00e8tre $\\tau$ de l'algorithme du gradient projet\u00e9, on pourra proc\u00e9der par t\u00e2tonnement: par exemple, choisir $\\tau$ de sorte \u00e0 ce que $k\\mapsto f(x^{(k)})$ soit d\u00e9croissante et que la suite $\\|{x^{k} - x^{(k-1)}}\\|$ semble tendre vers z\u00e9ro."]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"data": {"text/plain": ["[<matplotlib.lines.Line2D at 0x7ff08afa5c18>]"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}, {"data": {"image/png": "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\n", "text/plain": ["<Figure size 432x288 with 1 Axes>"]}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}, {"data": {"image/png": "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\n", "text/plain": ["<Figure size 432x288 with 1 Axes>"]}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}], "source": ["x = np.zeros(len(r))\n", "tau = .0005\n", "niter = 40\n", "F = np.zeros(niter)\n", "G = np.zeros(niter)\n", "for i in range(niter):\n", "    xnew = proj_simplexe(x - tau*gradf(x))\n", "    G[i] = np.linalg.norm(x-xnew)\n", "    F[i] = f(x)\n", "    x = xnew\n", "plt.plot(F)\n", "plt.figure()\n", "plt.semilogy(G)\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["## II.2. M\u00e9thode de p\u00e9nalisation\n", "\n", "**Q1** Montrer que le simplexe $\\Delta = \\{ x\\in\\Rsp_+^n\\mid \\sum_i x_i = 1\\}$ peut-\u00eatre mis sous la forme\n", "\n", "$$ \\Delta = \\{ x\\in\\Rsp^n \\mid \\forall 1\\leq i\\leq \\ell, c_i(x) \\leq 0 \\} $$\n", "\n", "avec $\\ell = n+2$ et \n", "\n", "$$ c_i(x) = \\begin{cases} -x_i & \\hbox{ si } 1\\leq i\\leq n \\\\\n", "x_1+\\dots+x_n - 1 & \\hbox{ si } i=n+1\\\\\n", "-(x_1+\\dots+x_n - 1) & \\hbox{ si } i=n+2\\end{cases} $$\n", "\n", "Dans la m\u00e9thode de p\u00e9nalisation, le probl\u00e8me d'optimisation sous contraintes \n", "\n", "$$ P =  \\min_{x\\in\\Delta} f(x) \\hbox{ o\u00f9 } f(x) = \\frac{1}{2}\\sca{x}{Qx} + \\frac{1}{2\\eta}(\\sca{r}{x}-r_0)^2, $$\n", "\n", "est alors approch\u00e9 par le probl\u00e8me d'optimisation sans contraintes suivant:\n", "\n", "$$ P_\\eps = \\min_{x\\in\\Rsp^n} f_\\eps(x) \\hbox{ o\u00f9 } f_\\eps(x) = f(x) + \\frac{1}{\\eps}\\sum_{1\\leq i\\leq \\ell} \\max(c_i(x),0)^2 $$\n", "\n", "**Q2** Montrer que \n", "\n", "$$ f_\\eps(x) = f(x) + \\frac{1}{\\eps}\\left(\\sum_{1\\leq i\\leq n} \\max(-x_i,0)^2)\\right) + \\frac{1}{\\eps}(x_1+\\dots+x_n - 1)^2 $$\n", "$$(\\nabla f_\\eps(x))_i = (\\nabla f(x))_i - \\frac{2}{\\eps} \\max(-x_i,0) + \\frac{2}{\\eps} (x_1+\\dots+x_n - 1)$$\n", "\n", "Coder deux fonctions `feps(x)` et `gradfeps(x)`, et v\u00e9rifier leur bon fonctionnement en utilisant `verifier_gradient`."]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["erreur numerique dans le calcul du gradient: 2.3825e-07 (doit etre petit)\n"]}], "source": ["eps = 1e-4\n", "\n", "def feps(x):\n", "    return f(x) + 1/eps*(np.sum(np.maximum(-x,0)**2))+ 1/eps*(np.sum(x)-1)**2\n", "\n", "def gradfeps(x):\n", "    return gradf(x) - 2/eps*np.maximum(-x,0) + 2/eps*(np.sum(x)-1)\n", "\n", "verifier_gradient(feps,gradfeps,10*(np.random.rand(len(r))-.5))"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["**Q3** En utilisant la fonction `gradient_armijo` ci-dessous, v\u00e9rifier le fonctionnement de cette approche pour des valeurs de `eps` mod\u00e9r\u00e9es ($\\eps = 10^{-2}$ o\u00f9 $10^{-3}$). Commenter les r\u00e9sultats (respect des contraintes, vitesse de convergence)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["iteration 100: f=27.378266, |g|=6.742202, step=0.000061\n", "iteration 200: f=27.290579, |g|=4.629492, step=0.000031\n", "iteration 300: f=27.249259, |g|=2.972122, step=0.000031\n", "iteration 400: f=27.235239, |g|=1.629654, step=0.000031\n", "iteration 500: f=27.230526, |g|=2.995748, step=0.000015\n", "iteration 600: f=27.228515, |g|=1.445854, step=0.000015\n", "iteration 700: f=27.227924, |g|=0.549317, step=0.000015\n", "iteration 800: f=27.227660, |g|=0.278880, step=0.000015\n", "iteration 900: f=27.227579, |g|=0.220608, step=0.000015\n", "iteration 1000: f=27.227547, |g|=0.213598, step=0.000015\n", "iteration 1100: f=27.227536, |g|=0.078490, step=0.000015\n", "iteration 1200: f=27.227532, |g|=0.025412, step=0.000122\n", "iteration 1300: f=27.227531, |g|=0.014321, step=0.000122\n", "iteration 1400: f=27.227530, |g|=0.012038, step=0.000031\n", "iteration 1500: f=27.227530, |g|=0.006354, step=0.000031\n", "iteration 1600: f=27.227530, |g|=0.007406, step=0.000015\n", "iteration 1700: f=27.227530, |g|=0.001910, step=0.000122\n", "iteration 1800: f=27.227530, |g|=0.002640, step=0.000015\n", "iteration 1900: f=27.227530, |g|=0.001165, step=0.000015\n", "iteration 2000: f=27.227530, |g|=0.000593, step=0.000015\n", "iteration 2100: f=27.227530, |g|=0.000263, step=0.000061\n", "iteration 2200: f=27.227530, |g|=0.000184, step=0.000031\n", "iteration 2300: f=27.227530, |g|=0.000096, step=0.000061\n", "iteration 2400: f=27.227530, |g|=0.000138, step=0.000015\n", "iteration 2500: f=27.227530, |g|=0.000032, step=0.000122\n", "iteration 2600: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 2700: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 2800: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 2900: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 3000: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 3100: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 3200: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 3300: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 3400: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 3500: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 3600: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 3700: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 3800: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 3900: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 4000: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 4100: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 4200: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 4300: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 4400: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 4500: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 4600: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 4700: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 4800: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 4900: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 5000: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 5100: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 5200: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 5300: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 5400: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 5500: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 5600: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 5700: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 5800: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 5900: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 6000: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 6100: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 6200: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 6300: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 6400: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 6500: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 6600: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 6700: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 6800: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 6900: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 7000: f=27.227530, |g|=0.000048, step=0.000000\n", "iteration 7100: f=27.227530, |g|=0.000048, step=0.000000\n"]}], "source": ["def gradient_armijo(f,gradf,x0,err=1e-5,maxiter=20000):\n", "    x = x0.copy()\n", "    fiter = []\n", "    giter = []\n", "    k = 0 # nombre d'it\u00e9rations\n", "    while(True): \n", "        k = k+1\n", "        if k > maxiter: # maximum de 10^6 it\u00e9rations\n", "            print('erreur: nombre maximum d\\'it\u00e9rations atteint')\n", "            break\n", "        d = -gradf(x)\n", "        fiter.append(f(x))\n", "        giter.append(np.linalg.norm(d))\n", "        if np.linalg.norm(d) <= err:\n", "            break\n", "        t = 1\n", "        m = -np.dot(d,d)\n", "        while f(x+t*d) > f(x) + 0.3*t*m:\n", "            t = 0.5*t\n", "        if k%100==0: # on affiche des informations toute les 100 it\u00e9rations\n", "            print('iteration %d: f=%f, |g|=%f, step=%f' % (k, f(x), np.linalg.norm(d),t))\n", "        x = x + t*d\n", "    return x,np.array(fiter),np.array(giter)\n", "\n", "x0 = np.ones(len(r))/len(r)\n", "x,fiter,giter = gradient_armijo(feps,gradfeps,x0,err=1e-5)\n", "plt.semilogy(giter)\n"]}, {"cell_type": "code", "execution_count": 31, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([0.12787167, 0.4879353 , 0.04085487, 0.34478116])"]}, "execution_count": 31, "metadata": {}, "output_type": "execute_result"}], "source": ["x"]}, {"cell_type": "code", "execution_count": 32, "metadata": {}, "outputs": [{"data": {"text/plain": ["1.0014429968281164"]}, "execution_count": 32, "metadata": {}, "output_type": "execute_result"}], "source": ["np.sum(x)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.0"}, "celltoolbar": "None"}, "nbformat": 4, "nbformat_minor": 2}