{"cells": [{"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["***\n", "## **Optimisation num\u00e9rique -- M1 Math&I.A. 2023/2024 -- Universit\u00e9 Paris-Saclay**\n", "***\n", "\n", "# TP 1: Minimisation de fonctionnelles quadratiques convexes\n", "\n", "$\\newcommand{\\Rsp}{\\mathbb{R}}\n", "\\newcommand{\\nr}[1]{\\|#1\\|}\n", "\\newcommand{\\abs}[1]{|#1|}\n", "\\newcommand{\\eps}{\\varepsilon}\n", "\\newcommand{\\sca}[2]{\\langle#1|#2\\rangle}\n", "\\newcommand{\\D}{\\mathrm{D}}\n", "\\newcommand{\\hdots}{\\dots}\n", "\\newcommand{\\cond}{\\mathrm{cond}}$\n", "\n", "## Pr\u00e9liminaires\n", "Dans ce TP, on s'int\u00e9resse \u00e0 la minimisation sur $\\Rsp^N$ de fonctionnelles de la forme suivante,\n", "\n", "$$ \n", "\\begin{aligned}\n", "f(x) &= \\frac{1}{2} \\sca{x}{Q x} + \\sca{b}{x} \\\\\n", "&= \\frac{1}{2} \\sum_{1\\leq i\\leq j \\leq N} Q_{ij} x_i x_j + \\sum_{1\\leq i\\leq N} b_i x_i,\n", "\\end{aligned} $$\n", "\n", "o\u00f9 $Q$ est une matrice sym\u00e9trique d\u00e9finie positive et $b$ est un vecteur colonne. Notre objectif principal est de constater num\u00e9riquement un ph\u00e9nom\u00e8ne expliqu\u00e9 en cours, \u00e0 savoir que l'efficacit\u00e9 des m\u00e9thodes de descente de gradient d\u00e9pend crucialement du *conditionnement* de la matrice $Q$ (voir ci-dessous pour une d\u00e9finition).\n", "\n", "**Quelques commentaires sur les Notebook.**\n", "Ce texte est r\u00e9dig\u00e9 sous la forme d'un notebook. Un notebook comporte des cellules de texte et des cellules de code, ici en Python. Quelques raccourcis clavier et remarques utiles:\n", "\n", "- `CTRL+Entr\u00e9e`: ex\u00e9cute la cellule de code, et affiche son r\u00e9sultat.\n", "- `Tab`: Si l'on `Tab` apr\u00e8s avoir tap\u00e9 les premi\u00e8res lettres d'un nom de fonction, le syst\u00e8me propose une liste de possibilit\u00e9s (ce qui peut permettre d'\u00e9viter des erreurs de frappe)\n", "- `MAJ+Tab`: Affiche la documentation sur la fonction. Tr\u00e8s utile pour ne pas se tromper sur l'ordre des param\u00e8tres. On peut voir une documentation plus compl\u00e8te en cliquant sur le '+'.\n", "- `CTRL+s`: Enregistrer les modifications apport\u00e9es au Notebook.\n", "- Le symbole `[*]` \u00e0 c\u00f4t\u00e9 d'une cellule de code indique que le noyau Python est toujours en train de calculer. On peut l'interrompre via `Kernel -> Interrupt` ou le red\u00e9marrer via `Kernel -> Restart`. Le noyau Python repart alors de z\u00e9ro, et il faut donc relancer les cellules ant\u00e9rieures \u00e0 celle sur laquelle on travaillait.\n", "\n", "Une aide compl\u00e8te, ainsi que la documentation de Python et Numpy, est disponible dans le menu `Aide`.\n", "\n", "**Rappels de cours et du TD pr\u00e9c\u00e9dent.**\n", "Ce TP ne n\u00e9cessite que quelques d\u00e9finitions et th\u00e9or\u00e8me du cours et des cours pr\u00e9c\u00e9dents, que l'on rappelle ici (le th\u00e9or\u00e8me de convergence ci-dessous sera d\u00e9montr\u00e9 un peu plus tard, dans un cas plus g\u00e9n\u00e9ral).\n", "\n", "> **Proposition:** Une fonction $f\\in\\mathcal{C}^2(\\Rsp^d)$ est convexe si pour tout $x\\in\\Rsp^d$, $D^2 f(x)$ est une matrice sym\u00e9trique positive, i.e. $\\forall x\\in\\Rsp^d,\\forall v\\in \\Rsp^d, \\sca{v}{D^2 f(x) v} \\geq 0$.\n", "\n", "> **Proposition:** Si $f \\in \\mathcal{C}^1(\\Rsp^d)$ est convexe, alors $x^* = \\arg\\min_{x\\in \\Rsp^d} f(x) \\Longleftrightarrow \\nabla f(x^*) = 0. $\n", "\n", "> **Th\u00e9or\u00e8me:** Toute matrice sym\u00e9trique $Q$ est diagonalisable dans une base orthonormale. En d\u2019autres mots, il existe une matrice orthogonale P telle que $ P^TQP$\n", "soit diagonale.\n", "\n", "> **D\u00e9finition:** On appelle *conditionnement* d'une matrice sym\u00e9trique d\u00e9finie positive $Q\\in M_N(\\Rsp)$ de valeurs propres $0< \\lambda_1\\leq \\dots \\leq \\lambda_N$ la quantit\u00e9 $\\cond(Q) = \\lambda_N / \\lambda_1$. \n", "\n", "> **Th\u00e9or\u00e8me:** Soit $f(x) = \\frac{1}{2} \\sca{x}{Q x} + \\sca{b}{x}$ o\u00f9 $Q$ est une matrice sym\u00e9trique d\u00e9finie positive, et soient  $(x^{(k)})_{k\\geq 0}$ les it\u00e9r\u00e9es de l'algorithme de descente de gradient \u00e0 pas optimal, c'est \u00e0 dire $x^{(0)} \\in \\Rsp^d$ et \n", "$$ \\begin{cases}\n", "d^{(k)} = -\\nabla f(x^{(k)})\\\\\n", "t^{(k)} = \\arg\\min_{t} f(x^{(k)} + t d^{(k)})  &\\hbox{ pour $k\\geq 0$}\\\\\n", "x^{(k+1)} = x^{(k)} + t^{(k)} d^{(k)}.\n", "\\end{cases}\n", "$$\n", "alors, avec $x^* = \\arg\\min_x f(x)$ et $c = 1 - \\cond(Q)^{-1} < 1$, on a\n", "$$ f(x^{(k+1)}) - f(x^*) \\leq c(f(x^{(k)}) - f(x^*)).$$\n", "\n", "## I. Gradient \u00e0 pas optimal en dimension $N=2$ \n", "\n", "Pour commencer, on commence par consid\u00e9rer la minimisation de la fonction $f_K:\\Rsp^2\\to\\Rsp$ d\u00e9finie par $f_K(x) = \\frac{1}{2}Kx_1^2 + \\frac{1}{2}x_2^2$ o\u00f9 $K$ est une constante strictement positive.\n", "\n", "**QI.1.** Calculer le gradient et la matrice hessienne de $f_K$, montrer que $f_K$ est convexe. Montrer que son unique minimiseur sur $\\Rsp^2$ est $x^* = (0,0)$.\n", "\n", "\n", "\n", "**QI.2.** \u00c9tant donn\u00e9 un point $x^{(k)} = (x_1^{(k)},x_2^{(k)}) \\in \\Rsp^2$ et $d^{(k)} = -\\nabla f_K(x)$, calculer le pas  optimal $t^{(k)}$. \n", "\n", "*(Indication: On pourra utiliser la formule g\u00e9n\u00e9rale pour le pas donn\u00e9e lors du TD1 (exercice 3) pour une fonction de la forme $f(x) = \\frac{1}{2}\\sca{x}{Qx} + \\sca{b}{x}$.)*\n", "\n", "\n", "\n", "**QI.3.** Programmer l'algorithme du gradient \u00e0 pas optimal, et le tester  pour $K=2$. On arr\u00eatera les it\u00e9rations d\u00e8s que $f_K(x^{(k)}) \\leq f_K(x^*) + 10^{-8}$.  Tracer deux figures :\n", "* les isovaleurs de $f_K$ (via les fonctions `numpy.meshgrid` et `plt.coutour`) ainsi que la trajectoire des it\u00e9r\u00e9es $(x_1^{(k)}, x_2^{(k)})_{k\\geq 1}$ (via les fonctions `plt.plot`)\n", "* l'\u00e9volution de l'erreur $\\log(f(x^{(k)}) - f(x^*))$ en fonction de $k$.\n", "Que se passe-t-il lorsque l'on change $K$ ?\n", "\n", "(*Indication: On pourra stocker la liste des it\u00e9r\u00e9es $x^{(k)}$ et des valeurs $f(x^{(k)})$ dans deux listes `X` et `F`, et utiliser la fonction `X.append(...)` pour ajouter un \u00e9l\u00e9ment \u00e0 la liste `X`. Pour l'erreur, on recommande la fonction `plt.semilogy`.*)\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# on importe les modules numpy et pyplot\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "# les deux commandes suivante param\u00e8trent l'affichage des figures\n", "%matplotlib inline\n", "plt.rcParams['figure.figsize'] = [9.,6.]\n", "\n", "# initialiser les variables K,Q, x0, fmin\n", "K = 10.\n", "X = [] # tableau pour stocker la liste des it\u00e9r\u00e9es x^k\n", "F = [] # tableau pour stocker la liste des valeurs f(x^k)\n", "x = np.array([1.,K]) \n", "\n", "# <completer>\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["**QI.4.** Recommencer l'exp\u00e9rience en choisissant $K = 10,100,500$. Calculer le taux de d\u00e9croissance moyen (c'est-\u00e0-dire la moyenne de $(f_K(x^{(k+1)})-f(x^*))/(f_K(x^{(k)}) - f(x^*)$) et le comparer \u00e0 la borne donn\u00e9e dans le th\u00e9or\u00e8me de convergence rappel\u00e9 en pr\u00e9liminaire.\n", "\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# <completer>\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["## II. Gradient \u00e0 pas optimal en dimension $N$\n", "\n", "On commence par \u00e9crire l'algorithme de gradient \u00e0 pas optimal pour minimiser sur   $\\Rsp^N$ une fonction de la forme $$f(x) = \\frac{1}{2} \\sca{Q x}{x} + \\sca{b}{x}$$\n", "o\u00f9 $Q$ est une matrice $N\\times N$ sym\u00e9trique d\u00e9finie positive et $b\\in\\Rsp^N$ est un vecteur.\n", "Lors du TD1 (exercices 2 et 3), nous avons vu que :\n", "* $\\nabla f(x) = Qx + b$, $\\mathrm{D}^2 f(x) = Q$\n", "* $f$ est convexe, et si $x^*$ est le minimiseur de $f$ sur $\\Rsp^N$, alors il v\u00e9rifie l'\u00e9quation $\\nabla f(x^*) = Qx^*+b = 0$.\n", "* l'algorithme de descente de gradient \u00e0 pas optimal s'\u00e9crit \n", "$$ \\begin{cases}\n", "d^{(k)} = -\\nabla f(x^{(k)})\\\\\n", "t^{(k)} = \\frac{\\sca{d^{(k)}}{d^{(k)}}}{\\sca{d^{(k)}}{Qd^{(k)}}}.  &\\hbox{ pour $k\\geq 0$}\\\\\n", "x^{(k+1)} = x^{(k)} + t^{(k)} d^{(k)}.\n", "\\end{cases}\n", "$$\n", "\n", "**QII.1** Programmer une fonction `gradient_optimal(Q,b,x0,err)`, prenant en argument la matrice $Q$, le vecteur $b$ et le point de d\u00e9part $x^{(0)}$, qui calculera les it\u00e9r\u00e9es de la m\u00e9thode de descente de gradient \u00e0 pas optimal (cf pr\u00e9liminaires). De plus,\n", "* Les it\u00e9rations seront interrompues lorsque $\\nr{d^{(k)}} \\leq $ `err` (on pourra utiliser la fonction `np.linalg.norm`) ou d\u00e8s que $k>10^6$.\n", "* La fonction retournera le dernier point $x^{(k)}$ trouv\u00e9 ainsi que deux vecteurs $E,F$ tels que $E^{(k)} = \\nr{d^{(k)}}$ et $F^{(k)} = f(x^{(k)})$. \n", "\n", "Tester cette fonction avec une matrice $Q = A^T A + \\mathrm{Id}$, o\u00f9 $A$ est une matrice al\u00e9atoire et $b$ est un vecteur al\u00e9atoire, pour $N=10$. On comparera la solution construite par l'algorithme de descente de gradient \u00e0 la solution exacte $x^* = -Q^{-1}b$ retourn\u00e9e par `-np.linalg.solve(Q,b)`.\n"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["def gradient_optimal(Q,b,x0,err=1e-6):\n", "    x = x0\n", "    niter=0\n", "    E = []\n", "    F = []\n", "    \n", "    k = 0 # nombre d'it\u00e9rations\n", "    while (True): \n", "        k = k+1\n", "        if k > 1e6: # maximum de 10^6 it\u00e9rations\n", "            print('erreur: nombre maximum d\\'it\u00e9rations atteint')\n", "            break\n", "        # calculer la direction de descente\n", "        # <completer>\n", "        # v\u00e9rifier le crit\u00e8re d'arr\u00eat, et quitter la boucle (avec break) s'il est v\u00e9rifi\u00e9\n", "        # <completer>\n", "        # calculer le pas de descente et mettre \u00e0 jour x\n", "        # <completer>\n", "    E = np.array(E)\n", "    F = np.array(F)\n", "    return x,E,F"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# test de la fonction gradient_optimal pour un Q,b al\u00e9atoire\n", "N = 10\n", "A = np.random.randn(N,N)\n", "Q = np.dot(A.T,A)+np.eye(N,N)\n", "b = np.random.rand(N)\n", "# <completer>\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["## III. Gradient \u00e0 pas optimal pour un probl\u00e8me de moindres carr\u00e9s "]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["**R\u00e9gression lin\u00e9aire:** On poss\u00e8de un jeu de donn\u00e9es constitu\u00e9 de points $(x_i,y_i)_{1\\leq i\\leq n} \\in\\Rsp^2$ et on cherche \u00e0 trouver $(\\mu_0, \\mu_1) \\in\\Rsp^2$ minimisant la fonction \n", "\n", "$$ f: \\mu\\in\\Rsp^2\\mapsto \\frac{1}{2} \\sum_{1 \\leq i \\leq n} |\\mu_0 + \\mu_1 x_i - y_i|^2. $$\n", "\n", "Ce probl\u00e8me d'optimisation peut \u00eatre interpr\u00e9t\u00e9 de la mani\u00e8re suivante. \u00c9tant donn\u00e9e une abscisse \u00e0 l'origine $\\mu_0$ et une  pente $\\mu_1$, on peut calculer la distance euclidienne  entre la donn\u00e9e $(x_i,y_i)$ et le point $(x_i,\\mu_0 + \\mu_1 x_i)$ qui appartient \u00e0 la droite \n", "$\\mathcal{D} = \\{ (x,y) \\mid y = \\mu_0 + \\mu_1 x\\}$, soit\n", "$$\\eps_i = |\\mu_0 + \\mu_1 x_i - y_i|$$\n", "Le probl\u00e8me d'optimisation pr\u00e9c\u00e9dent consiste \u00e0 trouver une droite d'abscisse \u00e0 l'origine $\\mu_0$ et de pente $\\mu_1$ minimisant la somme des erreurs $\\eps_1^2 + \\hdots + \\eps_n^2$, et passant donc au plus pr\u00e8s du jeu de donn\u00e9es. Cette m\u00e9thode a \u00e9t\u00e9 invent\u00e9e simultan\u00e9ment par Gauss et [Legendre](http://www.bibnum.education.fr/sites/default/files/legendre-texte.pdf).\n", "\n", "Pour nos exp\u00e9riences, les points de donn\u00e9es $(x_i,y_i)$ sont construits de la mani\u00e8re suivante:"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/plain": ["<matplotlib.legend.Legend at 0x7f8753db73d0>"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}, {"data": {"image/png": "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\n", "text/plain": ["<Figure size 900x600 with 1 Axes>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["n=50\n", "X = np.linspace(-1,1,n);\n", "Y = np.sin(np.pi*X) + .1*np.random.rand(n)\n", "plt.plot(X,Y,'.',label='donnees')\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["**QIII.1** Construire une matrice $A$ ayant $n$ lignes et $2$ colonnes telle que le vecteur $Z := (\\mu_0 + \\mu_1 x_i)_{1\\leq i\\leq n}$ s'\u00e9crive $Z = A\\mu$ (produit matrice vecteur). Remarquer que l'on peut alors \u00e9crire $f(\\mu) = \\frac{1}{2} \\nr{A \\mu - Y}^2$ o\u00f9 $Y = (y_i)_{1\\leq i\\leq n}$.\n", "\n", "\n", "**Remarque :** Lors du TD1 (exercice 4), nous avons vu que la fonction $f(\\mu) = \\nr{A \\mu - Y}^2$ peut \u00eatre mise sous la forme $$f(\\mu)=\\frac{1}{2}\\sca{\\mu}{Q \\mu} + \\sca{b}{\\mu} + c,$$\n", "o\u00f9 $Q = A^T A$, $b = - A^T Y$ et $c = \\frac{1}{2}Y^T Y$.\n", "On a aussi montr\u00e9 que si la matrice $A$ injective alors $Q$ est sym\u00e9trique d\u00e9finie positive.\n", "\n", "**QIII.2** Calculer le minimum  $\\mu^*$ de $f$ \u00e0 l'aide de la fonction `gradient_optimal`, tracer sur une m\u00eame figure les points $(X,Y)$ et la droite $(X, A\\mu^*)$. V\u00e9rifier la correction du r\u00e9sultat en le comparant \u00e0 celui obtenu en r\u00e9solvant le syst\u00e8me lin\u00e9aire $\\nabla f(\\mu^*) = 0$."]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# calculer A, Q, b, puis appliquer l'algorithme du gradient \u00e0 pas optimal\n", "# <completer>\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["**R\u00e9gression polyn\u00f4miale** On s'int\u00e9resse maintenant \u00e0 une g\u00e9n\u00e9ralisation du probl\u00e8me de r\u00e9gression lin\u00e9aire. Il s'agit cette fois-ci d'approcher au mieux le jeu de donn\u00e9es $(x_i,y_i)_{1\\leq i\\leq n}$ par des points de la forme $(x_i,P_\\mu(x_i))_{1\\leq i\\leq N}$ o\u00f9 $P_\\mu(X) = \\sum_{0\\leq i\\leq d} \\mu_i X^i$ est un polyn\u00f4me de degr\u00e9 $d$ \u00e0 d\u00e9terminer. L'inconnue de notre probl\u00e8me est donc le vecteur $\\mu \\in \\Rsp^{d+1}$, qu'on choisit via le probl\u00e8me d'optimisation suivant:\n", "$$ \\min_{\\mu \\in \\Rsp^{d+1}} \\frac{1}{2} \\sum_{1\\leq i\\leq N} \\nr{P_\\mu(x_i) - y_i}^2, $$\n", "\n", "**QIII.3** Montrer que ce probl\u00e8me est \u00e9quivalent au probl\u00e8me suivant:\n", "$$ \\min_{(\\mu_0,\\hdots,\\mu_d) \\in \\Rsp^{d+1}} f_d(\\mu) := \\frac{1}{2} \\nr{A_d \\mu - Y}^2 \\quad \\hbox{ o\u00f9 } A_d = \\begin{pmatrix} 1 & x_1 & x_1^2 & \\hdots & x_1^d \\\\\n", "1 & x_2 & x_2^2 & \\hdots & x_2^d \\\\\n", "\\vdots & \\vdots & \\vdots & &\\vdots \\\\\n", "1 & x_n & x_n^2 & \\hdots & x_n^d,\n", "\\end{pmatrix}$$\n", "puis que $f_d$ est convexe et m\u00eame strictement convexe si les points $x_i$ sont distincts deux \u00e0 deux.\n", "\n", "\n", "\n", "\n", "**QIII.4** R\u00e9soudre le probl\u00e8me d'optimisation pour $2\\leq d \\leq 7$ via la fonction `gradient_optimal`, en fixant `err=1e-4`. Interpr\u00e9ter l'accroissement du nombre d'it\u00e9rations de l'algorithme en calculant le conditionnement des matrices $A_d$ via la fonction `np.linalg.cond`."]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["# on commence par construire la matrice A pour d=2, en guise d'exemple:\n", "A = np.vstack([X**0, X**1, X**2]).T\n", "# ou, de mani\u00e8re \u00e9quivalente\n", "A = np.vstack([X**i for i in range(3)]).T\n", "\n", "# <completer>\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["**QIII.5** On pose $g_d(\\mu) = f_d(\\mu) + \\frac{\\gamma}{2}\\sum_{0\\leq i\\leq d} \\mu_i^2$. Mettre $g_d$ sous la forme \n", "$$ g_d(\\mu) := \\frac{1}{2} \\sca{\\mu}{R_d \\mu} + \\sca{b_d}{T} \\mu + c_d $$\n", "et d\u00e9montrer que $\\cond(R_d) < \\cond(Q_d)$ o\u00f9 $Q_d:=A^T_d A_d$. V\u00e9rifier que l'algorithme du gradient \u00e0 pas optimal converge plus rapidement.\n", "\n"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["# <completer>\n"]}, {"cell_type": "markdown", "metadata": {"deletable": false}, "source": ["## IV Exercice (valeurs propres et conditionnement)\n", "\n", "**QIV.1** Soit $Q$ une matrice sym\u00e9trique de taille $d\\times d$ et $\\lambda_1\\leq \\hdots\\leq \\lambda_d$ ses valeurs propres. \n", "D\u00e9montrer que pour tout $\\mu \\in \\Rsp^d$, \n", "$$ \\lambda_1 \\nr{\\mu}^2 \\leq \\sca{\\mu}{Q\\mu} \\leq \\lambda_d \\nr{\\mu}^2. $$\n", "En d\u00e9duire que \n", "$$ \\lambda_1 = \\min_{\\mu \\neq 0} \\frac{\\sca{\\mu}{Q\\mu}}{\\nr{\\mu}^2} \\qquad \n", "\\lambda_d = \\max_{\\mu \\neq 0} \\frac{\\sca{\\mu}{Q\\mu}}{\\nr{\\mu}^2} $$\n", "\n", "\n", "\n", "**QIV.2** On consid\u00e8re maintenant la matrice $Q_d = A_d^T A_d$ o\u00f9 $A_d$ est d\u00e9finie en QIII.3. \n", "En consid\u00e9rant $\\mu = (1,0,\\hdots,0)$ (resp. $\\mu = (0,\\hdots,0,1)$) \n", "d\u00e9montrer que \n", "$$\\lambda_d \\geq n \\qquad (\\hbox{resp. } \\lambda_1 \\leq \\sum_{1\\leq i\\leq n} x_i^{2d})$$\n", "En d\u00e9duire une minoration de $\\cond(Q_d)$ ne faisant intervenir que $n$ et $d$.\n", "\n"]}], "metadata": {"celltoolbar": "None", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.16"}}, "nbformat": 4, "nbformat_minor": 1}